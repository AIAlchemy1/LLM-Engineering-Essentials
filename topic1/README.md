# Topic 1. LLM API Basics

**The course is under construction, with new materials appearing regularly.**

**Subscribe for updates and make sure you don’t miss anything: [Stay updated](https://academy.nebius.com/llm-engineering-essentials/update/)**

## Contents

* **1.1. Intro to LLM APIs** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.1_intro_to_llm_apis.ipynb)

  Experiment with text-to-image and image-to-text generation, send API requests, and analyze responses using OpenAI API and [Nebius AI Studio](https://studio.nebius.ai/), which provides open-source models like Llama, Mistral, DeepSeek, and Qwen. 
  This section will ensure you can make API calls, handle responses, and integrate LLMs into applications.

* **1.2. Tokenization** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.2_tokenization.ipynb)

  For LLMs, text is composed of tokens, which can be words, subwords, individual characters, or even byte sequences.
  In this chapter, you'll learn what tokens are and how tokenization affects the way LLMs process text.

* **1.3. Basic prompting guidelines** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.3_basic_prompting_guidelines.ipynb)

  In this chapter, we'll share some basic practical hints for prompting LLMs.

* **1.4. What can possibly go wrong with an LLM** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.4_what_can_possibly_go_wrong_with_an_llm.ipynb)

  Learn about some of the blights that plague LLM users: hallucinations, bias, mode collapsing, and jailbreaks.

* **1.5. Choosing an LLM** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.5_how_to_choose_an_llm.ipynb)

  Learn about various cosiderations that you can use to choose LLMs for your projects, including size tiers, benchmarks, reasoning capabilities, etc.

* **1.6. LLM Inference Parameters** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.6_llm_inference_parameters.ipynb)

  Understand token probabilities, uncertainty, and the LLM generation process. 
  Learn how inference parameters influence randomness in responses and how to balance reproducibility and creativity.


* **1.7. Creating an LLM-powered Character** [colab link](https://colab.research.google.com/github/Nebius-Academy/LLM-Engineering-Essentials/blob/main/topic1/1.7_creating_an_llm-powered_character.ipynb)

  Build a chatbot based on a fantasy character and explore advanced features like giving it a scratchpad — a space for its own "thoughts."
