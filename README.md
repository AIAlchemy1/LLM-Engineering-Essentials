# LLM Engineering Essentials course by Nebius Academy

**The course is under construction, with new materials appearing regularly.**

**Subscribe for updates and make sure you donâ€™t miss anything: [Stay updated](https://academy.nebius.com/llm-engineering-essentials/update/)**

This is an open course on using and deploying LLM APIs and open-source LLMs.

Materials for each topic can be found in the ./topic* folders. See README.md for further details and instructions.

The course includes a capstone project: NPC (Non-Playable Character) Factory Development. In this project, you'll build a service based on either an LLM API or an open-source LLM to provide NPC interactions for users. You'll go through the entire process, from personalizing a chat bot to making a cost-and-quality decision between using an API or hosting an LLM on your own servers.


Any technical issues, ideas, bugs in course materials, contribution ideas - add an issue.

# Syllabus

# Topic 1. LLM API Basics

Basics of LLM and Multimodal LLM API usage and prompt strategies, typical problems arising with LLMs, creativity-vs-reproducibility control.

**Project**: Creating a chatbot and deploying it in a cloud.

# Topic 2. LLM Workflows

LLM Workflows and beyond: from Chaining to AI Agents. LLM Reasoning.

**Project**: Planning and memory summarization; Automating evaluation.
	
# Topic 3. Context

RAG and its technicalities; vector stores, databases in production. RAG evaluation.

**Project**: Adding RAG to the NPC Factory service.

# Topic 4. Self-Served LLMs
	
Working with open source LLMs and practical LLM inference in production. Computational and memory bottlenecks of LLM inference.

**Project**: Deploying a chat service based on a self-served LLM. Serving text encoders and rerankers. Making a cost-to-value choice between API and self-served LLMs.
	
# Topic 5. Optimization and Monitoring

Optimizing LLM inference, quantization and beyond. Production monitoring and observability.
	
**Project**: Optimizing open source LLM inference. Establishing monitoring with Evidently AI, Prometeus and Grafana.
	
# Topic 6. Fine Tuning

Fine tuning of LLMs and embeddings. Parameter-Efficient Fine Tuning and LoRA. RLHF and DPO
	
Project: Making your characters even more alive through fine tuning

